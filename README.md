# ğŸ‡®ğŸ‡³ Multilingual RAG-Powered Virtual Assistant for Government Examination Preparation using Azure OpenAI, LangChain, and Microsoft Fabric Eventhouse

---

## ğŸ§­ Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Prerequisites](#prerequisites)
- [OpenAI Models Used](#openai-models-used)
- [Architecture](#architecture)
- [How It Works](#how-it-works)
- [Setup](#setup)
- [Dashboard](#dashboard)
- [Output](#output)
- [Conclusion](#conclusion)
- [License](#license)
- [Contributing](#contributing)

---

## ğŸŒ Overview

The **Multilingual RAG-Powered Virtual Assistant** is an AI-driven solution built using **Azure OpenAI**, **LangChain**, and **Microsoft Fabric Eventhouse**.  
It automates the ingestion of **PDF documents** from **official government websites** (via web scraping) and **manual uploads**, assisting students preparing for **government and competitive exams in India**.

This assistant provides **accurate, multilingual, and real-time** information such as notifications, eligibility, and exam schedules â€” directly from verified PDFs.

### ğŸ¯ Advantages
- Fetches official, verified updates (UPSC, IBPS, SSC, etc.)
- Provides multilingual answers (English, Hindi, and others)
- Extracts both text and tables
- Reduces manual searching across sites
- Uses **Eventhouse** for scalable, vector-based search
- Avoids duplicates using stable `chunk_id`
- Combines **RAG + GPT** for context-based answers

---

## ğŸš€ Features

| Feature | Description |
|----------|--------------|
| ğŸ“„ PDF Ingestion | Extracts both text and tables from multiple PDFs |
| ğŸŒ Multilingual Support | Answers queries in several Indian languages |
| ğŸ§  RAG Architecture | Uses embeddings + GPT for contextual answers |
| ğŸ’¾ Eventhouse Integration | Stores text, embeddings, and metadata |
| ğŸ§¾ Deduplication | Stable hash-based chunk identification |
| ğŸ“Š Dashboard | KQL-based ingestion and language insights |
| âš¡ Modular Design | Clear, reusable Fabric notebooks |

---

## ğŸ§© Prerequisites

You need access to:

- âœ… **Microsoft Fabric Account** (Lakehouse + Eventhouse)
- âœ… **Azure OpenAI Studio** (model deployment rights)
- âœ… **Deployed Azure OpenAI Resource** (GPT + embeddings)
- âœ… **Fabric Workspace Setup** (edit + contributor access)
- âœ… **Python Runtime** (Fabric or local conda environment)

---

## ğŸ§  OpenAI Models Used

| Model | Purpose | Description |
|--------|----------|-------------|
| **`text-embedding-ada-002`** | Embedding | Converts text and tables into dense numerical vectors for similarity-based search |
| **`gpt-4o` / `gpt-35-turbo`** | Language Model | Answers queries contextually using retrieved chunks from Eventhouse |

These models combine to create a **Retrieval-Augmented Generation (RAG)** pipeline that supports multilingual Q&A.

---

## ğŸ—ï¸ Architecture

This system integrates **Azure OpenAI**, **LangChain**, and **Microsoft Fabric** components for an end-to-end RAG workflow.

![Architecture Diagram](images/architecture.png)

### Components
1. **Fabric Lakehouse** â†’ stores PDFs and text extractions  
2. **Fabric Notebooks** â†’ extract, chunk, embed, and upload data  
3. **Azure OpenAI** â†’ generates embeddings and answers  
4. **Eventhouse DB** â†’ stores embeddings and metadata  
5. **KQL Dashboard** â†’ monitors ingestion and data metrics
---

## ğŸ’¡ How It Works

The RAG pipeline consists of two main phases â€” **indexing** and **retrieval**.

### ğŸ§± Step 1: Processing the Files and Indexing the Embeddings

This step prepares and stores vector embeddings into **Fabric Eventhouse**.

1. **Read PDF documents** from Fabric Lakehouse  
2. **Extract both text and tables** using `PyPDFLoader` and `pdfplumber`  
3. **Generate embeddings** using the `text-embedding-ada-002` model  
4. **Store both text and embeddings** into Eventhouse (`embeddingtables`)

ğŸ“¸ *Add diagram:*  
![Processing and Indexing Flow](images/ingestion_flow.png)

---

### ğŸ’¬ Step 2: RAG â€“ Getting Answers

1. Convert the question into an embedding  
2. Search that embedding against Eventhouse vectors  
3. Retrieve top-matching chunks  
4. Combine them with the query and pass to **GPT-4o**  
5. GPT returns a fluent, multilingual answer  

ğŸ“¸ *Add diagram:*  
![RAG Retrieval Flow](images/query_flow.png)

---

## âš™ï¸ Setup

### ğŸ§© Step 1 â€“ Create a Fabric Workspace  
Create a workspace named **GovExamAssistant** in Microsoft Fabric.

### ğŸ§© Step 2 â€“ Create a Lakehouse  
Create a Lakehouse named `govexam-lakehouse` for storing PDFs and extracted data.

### ğŸ§© Step 3 â€“ Upload PDFs  
Upload exam PDFs (IBPS, UPSC, DDA, SSC etc.) manually or from a scraping script to:

### ğŸ§© Step 4 â€“ Create an Eventhouse  
Create an **Eventhouse** database named `govexam_eventhouse`.

### ğŸ§© Step 5 â€“ Create the Embeddings Table  
Create a table named `embeddingtables` with columns:  
`doc_id, document_name, source_url, page_no, chunk_no, content, embedding, chunk_id, content_type, lang, ingest_time`

### ğŸ§© Step 6 â€“ Import and Configure Notebooks  
Upload:
- `01_ingest_pdfs.ipynb` â€“ extracts & splits data  
- `02_generate_embeddings.ipynb` â€“ creates embeddings  
- `03_query_rag_engine.ipynb` â€“ performs Q&A  

### ğŸ§© Step 7 â€“ Connect to Eventhouse  
Set the following inside your notebook:

```python
KUSTO_URL = "<your-eventhouse-cluster-url>"
KUSTO_DATABASES = "govexam_eventhouse"
KUSTO_TABLES = "embeddingtables"



